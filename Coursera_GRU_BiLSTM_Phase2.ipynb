{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "em2e6ukUcSbg",
    "outputId": "bb993135-d77f-4977-b329-46d36a49a198"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]\n",
      "Selected Jupyter core packages...\n",
      "IPython          : 7.34.0\n",
      "ipykernel        : 6.29.4\n",
      "ipywidgets       : 8.1.3\n",
      "jupyter_client   : 7.4.9\n",
      "jupyter_core     : 5.7.2\n",
      "jupyter_server   : 2.14.1\n",
      "jupyterlab       : 4.2.2\n",
      "nbclient         : 0.10.0\n",
      "nbconvert        : 7.16.4\n",
      "nbformat         : 5.10.4\n",
      "notebook         : 6.5.6\n",
      "qtconsole        : 5.5.2\n",
      "traitlets        : 5.14.3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)\n",
    "!jupyter --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.10.1 in c:\\users\\amit1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.10.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\amit1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.10.1) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\amit1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.10.1) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\amit1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.10.1) (24.3.25)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\amit1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.10.1) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\amit1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.10.1) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\amit1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.10.1) (3.11.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\amit1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.10.1) (1.1.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\amit1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.10.1) (18.1.1)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\amit1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.10.1) (1.23.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\amit1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.10.1) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\amit1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.10.1) (24.1)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\amit1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.10.1) (3.19.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\amit1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.10.1) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\amit1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.10.1) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\amit1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.10.1) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\amit1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.10.1) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\amit1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.10.1) (1.16.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\amit1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.10.1) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\amit1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.10.1) (1.64.1)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in c:\\users\\amit1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.10.1) (2.10.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in c:\\users\\amit1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.10.1) (2.10.0)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in c:\\users\\amit1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.10.1) (2.10.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\amit1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from astunparse>=1.6.0->tensorflow==2.10.1) (0.43.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\amit1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.1) (2.30.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\amit1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.1) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\amit1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.1) (3.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\amit1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.1) (2.32.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\amit1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.1) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\amit1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.1) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\amit1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.1) (3.0.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\amit1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\amit1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\amit1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\amit1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (2.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\amit1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\amit1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\amit1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\amit1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (2024.6.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\amit1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (2.1.5)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\amit1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (0.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\amit1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\amit1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\amit1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\amit1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\amit1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\amit1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\amit1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "#pip install tensorflow==2.10.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.python.saved_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27240\\926589766.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtyping\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_typing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;31m# Bring in subpackages.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;31m# from tensorflow.python import keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mexperimental\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAUTOTUNE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mservice\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatching\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdense_to_ragged_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatching\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdense_to_sparse_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\service\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    417\u001b[0m \"\"\"\n\u001b[0;32m    418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 419\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_service_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    420\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_service_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfrom_dataset_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_service_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mregister_dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\data_service_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mservice\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_pywrap_server_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mservice\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_pywrap_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdataset_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moptions\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moptions_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstructured_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgraph_pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moptions\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moptions_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstructured_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgen_dataset_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrackable\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbase\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtrackable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaver\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBaseSaverBuilder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_pywrap_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeprecation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf_logging\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpywrap_saved_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrackable\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbase\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtrackable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpy_checkpoint_reader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.python.saved_model'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XlaNlc96cshB",
    "outputId": "5317546f-6a5e-4d37-c682-bb2209023867"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.python.saved_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27240\\3570661566.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtyping\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_typing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;31m# Bring in subpackages.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;31m# from tensorflow.python import keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mexperimental\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAUTOTUNE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mservice\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatching\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdense_to_ragged_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatching\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdense_to_sparse_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\service\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    417\u001b[0m \"\"\"\n\u001b[0;32m    418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 419\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_service_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    420\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_service_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfrom_dataset_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_service_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mregister_dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\data_service_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mservice\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_pywrap_server_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mservice\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_pywrap_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdataset_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moptions\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moptions_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstructured_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgraph_pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moptions\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moptions_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstructured_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgen_dataset_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrackable\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbase\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtrackable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaver\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBaseSaverBuilder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_pywrap_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeprecation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf_logging\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpywrap_saved_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrackable\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbase\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtrackable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpy_checkpoint_reader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.python.saved_model'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, LSTM, Dropout, Activation, Embedding,SimpleRNN,GRU\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "from string import punctuation\n",
    "punct = list(punctuation)\n",
    "from tqdm import tqdm\n",
    "from keras.callbacks import ReduceLROnPlateau,EarlyStopping\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Up171h2exBc"
   },
   "source": [
    "### Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "ApVy3QScc934",
    "outputId": "001c3a0f-81c7-46e9-aa1a-f3a420b816b4"
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv('C:\\MY FILES\\Thesis\\Coursera_review\\Final notebooks\\dataset_small.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "EQBy8YMxfZre",
    "outputId": "44b963d4-9a7e-4730-a6c5-19a6875f79ac"
   },
   "outputs": [],
   "source": [
    "# Renaming columns\n",
    "data = data.rename(columns={'Label':'Rating'})\n",
    "data = data.rename(columns={'CourseId':'CourseName'})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IJs_ABeHgcp3",
    "outputId": "cb522caf-19db-40ce-aa1f-b1abd6302bff"
   },
   "outputs": [],
   "source": [
    "# Analysing dataframe attributes\n",
    "print('* Size of dataframe: {}\\n'.format(data.shape))\n",
    "print('* Datatype of columns are:\\n {}\\n'.format(data.dtypes))\n",
    "print('* Count of different product categories:\\n {}\\n'.format(data['Rating'].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "D1xrrybngiJD",
    "outputId": "902dd1d8-3bac-47d5-a335-b2d514a64314"
   },
   "outputs": [],
   "source": [
    "# Plotting word lenghts of reviews\n",
    "data['Review'] = data['Review'].astype(str)\n",
    "word_length = [len(x) for x in data['Review']]\n",
    "plt.plot(word_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1zPDD6ssgrrX",
    "outputId": "681d6cde-16ea-4796-d5be-da0ca99f3f1e"
   },
   "outputs": [],
   "source": [
    "# Types of ratings\n",
    "data['Rating'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PyGxlO4phKqr"
   },
   "source": [
    "### Checking for Class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "C9CXMapihSMm",
    "outputId": "8c16ab80-1d24-4ca5-f69f-aa702ecf7174"
   },
   "outputs": [],
   "source": [
    "sns.countplot(x=data['Rating'], data=data, hue=data['Rating'], palette='RdBu')\n",
    "plt.xticks([0,1,2,3,4,5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "tb5doCWbhZ1A",
    "outputId": "0d254404-ec9b-4e0e-e7bc-42e758709996"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w6889AaxhgqQ"
   },
   "source": [
    "### Handling class imbalance problem using imblearn's random over sampling technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "GEySaUX0hdF5",
    "outputId": "03f9fcd4-d24f-44e9-b3b0-1ff5a7eee181"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "# define oversampling strategy\n",
    "oversample = RandomOverSampler(sampling_strategy='all')\n",
    "# fit and apply the transform\n",
    "#X = data.drop(columns=['Rating','CourseName'])\n",
    "X = data[['Review']]\n",
    "y = data['Rating']\n",
    "X_over, y_over = oversample.fit_resample(X, y)\n",
    "sns.countplot(x=y_over, data=data, hue=y_over, palette='RdBu')\n",
    "plt.xticks([0,1,2,3,4,5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fhUnhR7Dh5IY",
    "outputId": "39b7c0d5-6f89-4be8-a52e-1b1aef8a12b8"
   },
   "outputs": [],
   "source": [
    "X_over.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qZLr78L_h5qI",
    "outputId": "a3bcceaa-a04f-4abe-8fd2-85de1ac429f0"
   },
   "outputs": [],
   "source": [
    "y_over.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FVDHgW12iGfR",
    "outputId": "30045de1-1fce-434d-edd3-e72d810d1bdd"
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b0p5TcOQiKlm"
   },
   "source": [
    "### Combining oversampled columns to create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iJKmZpiRiL_7"
   },
   "outputs": [],
   "source": [
    "data_over = pd.concat([X_over, y_over], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R32hHTRpiiUl",
    "outputId": "a85b0321-f799-4dea-dc0f-309f843a9dcd"
   },
   "outputs": [],
   "source": [
    "data_over.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "o9Zy2cYOimC4",
    "outputId": "a42d6fc3-524f-4c2d-d3c8-0076149d5cfa"
   },
   "outputs": [],
   "source": [
    "data_over.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTCF8a7xiuJn"
   },
   "source": [
    "### Train-Test Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PvfbX3IwitYO"
   },
   "outputs": [],
   "source": [
    "# Importing train test splilt library\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Train-Test Splitting\n",
    "train_data, test_data = train_test_split(data_over, test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L8LNr4ffi1yX",
    "outputId": "a86281ef-54a1-4c12-d16e-3e976f4b8f3c"
   },
   "outputs": [],
   "source": [
    "len(train_data),len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sQkufmsgi75i"
   },
   "source": [
    "### Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ay2vXZWui9Ak"
   },
   "outputs": [],
   "source": [
    "# Importing NLTK Libraries\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dcYQT2ShjH8C"
   },
   "outputs": [],
   "source": [
    "# Declaring function for text preprocessing\n",
    "\n",
    "def preprocess_text(main_df):\n",
    "  df_1 = main_df.copy()\n",
    "\n",
    "  # remove stopwords\n",
    "  nltk.download('stopwords')         # Downloading stopwords\n",
    "  stop = stopwords.words('english')\n",
    "  df_1['Review'] = df_1['Review'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "\n",
    "  # remove punctuations and convert to lower case\n",
    "  df_1['Review'] = df_1['Review'].apply(lambda x: re.sub('[!@#$:).;,?&]', '', x.lower()))\n",
    "\n",
    "  # remove double spaces\n",
    "  df_1['Review'] = df_1['Review'].apply(lambda x: re.sub(' ', ' ', x))\n",
    "\n",
    "  return df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YDvsoMM1jJrl",
    "outputId": "8bd0cf3b-59ee-4da3-e05d-e78e7561d559"
   },
   "outputs": [],
   "source": [
    "# Preprocessing training and test data\n",
    "train_data = preprocess_text(train_data)\n",
    "test_data = preprocess_text(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zNqD-oHnjROh",
    "outputId": "7b99688a-c91a-4bbe-94a8-0cb476fa5b46"
   },
   "outputs": [],
   "source": [
    "# Verifying text preprocessing\n",
    "train_data['Review'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E5U1OZB1jdPE"
   },
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qok4hGtojSNO"
   },
   "outputs": [],
   "source": [
    "# Declaring train labels\n",
    "train_labels = train_data['Rating']\n",
    "test_labels = test_data['Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0M9TQ69cjh41",
    "outputId": "4f56f0ca-b62d-4a4b-e7fd-e8977209d273"
   },
   "outputs": [],
   "source": [
    "# Converting labels to numerical features\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(train_labels)\n",
    "train_labels = le.transform(train_labels)\n",
    "test_labels = le.transform(test_labels)\n",
    "\n",
    "print(le.classes_)\n",
    "print(np.unique(train_labels, return_counts=True))\n",
    "print(np.unique(test_labels, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bYvOW5pljqia"
   },
   "outputs": [],
   "source": [
    "# Changing labels to categorical features\n",
    "import numpy as np\n",
    "from tensorflow.python.keras.utils import np_utils\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "train_labels = to_categorical(np.asarray(train_labels))\n",
    "test_labels = to_categorical(np.array(test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UtVcxHs3jtDN"
   },
   "source": [
    "### Tokenizing Sentences and Fixing Sentence Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u7jdHbw-juV2"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Defining training parameters\n",
    "max_sequence_length = 200\n",
    "max_words = 2500\n",
    "\n",
    "# Tokenizing Reviews/sentences wrt num_words\n",
    "tokenizer = Tokenizer(num_words = max_words)  # Selects most frequent words\n",
    "tokenizer.fit_on_texts(train_data.Review)      # Develops internal vocab based on training text\n",
    "train_sequences = tokenizer.texts_to_sequences(train_data.Review)  # converts text to sequence\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences(test_data.Review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6n1b2MjajzMX",
    "outputId": "4d8afcfc-0c32-4fbc-d2fb-b4c55d778d7b"
   },
   "outputs": [],
   "source": [
    "# Fixing the sequence length\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "train_data = pad_sequences(train_sequences, maxlen = max_sequence_length)\n",
    "test_data = pad_sequences(test_sequences, maxlen = max_sequence_length)\n",
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xBqtaZxqj5zS"
   },
   "source": [
    "### Declaring GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BGmi8fo3j6_H",
    "outputId": "6e326dfb-ec82-46f5-c23f-a55b99c27931"
   },
   "outputs": [],
   "source": [
    "embedding_dim = 64\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(max_words,\n",
    "                   embedding_dim,\n",
    "                   input_length=max_sequence_length))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(GRU(units =32))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5,activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-LD0gfxkBO1"
   },
   "source": [
    "### Training GRU Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VyqD86WdkAs1",
    "outputId": "c8c1b5ea-10c0-4081-e62c-e2756911b724"
   },
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3)\n",
    "early_stop=EarlyStopping(monitor='val_loss',patience=10)\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "history = model.fit(train_data, train_labels, epochs=5,\n",
    "                    validation_data=(test_data, test_labels),\n",
    "                    callbacks=[reduce_lr,early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PDvgqF5nv_OM",
    "outputId": "d1e2c296-85bf-4911-c7bb-315e86bc87c0"
   },
   "outputs": [],
   "source": [
    "# Prediction on Test Data\n",
    "predicted_gru = model.predict(test_data)\n",
    "predicted_gru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s1KHT6CSwNcq"
   },
   "source": [
    "### GRU Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1W7AFdLkwKjs",
    "outputId": "333b506f-cf24-4ae0-fd71-83b650269155"
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "precision, recall, fscore, support = score(test_labels, predicted_gru.round())\n",
    "\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))\n",
    "print('################################')\n",
    "print(sklearn.metrics.classification_report(test_labels, predicted_gru.round()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pW6DpBXbw5Ha"
   },
   "source": [
    "### Model Performance with Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 432
    },
    "id": "FdOQiI6tw4hc",
    "outputId": "2fb70f8e-0881-4efc-990a-f9ce8aa1a143"
   },
   "outputs": [],
   "source": [
    "def accuracy_plot(history):\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10,4))\n",
    "\n",
    "    fig.suptitle('Model Performance with Epochs', fontsize = 16)\n",
    "    # Subplot 1\n",
    "    ax[0].plot(history.history['accuracy'])\n",
    "    ax[0].plot(history.history['val_accuracy'])\n",
    "    ax[0].set_title('Model Accuracy', fontsize = 14)\n",
    "    ax[0].set_xlabel('Epochs', fontsize = 12)\n",
    "    ax[0].set_ylabel('Accuracy', fontsize = 12)\n",
    "    ax[0].legend(['train', 'validation'], loc='best')\n",
    "\n",
    "    # Subplot 2\n",
    "    ax[1].plot(history.history['loss'])\n",
    "    ax[1].plot(history.history['val_loss'])\n",
    "    ax[1].set_title('Model Loss', fontsize = 14)\n",
    "    ax[1].set_xlabel('Epochs', fontsize = 12)\n",
    "    ax[1].set_ylabel('Loss', fontsize = 12)\n",
    "    ax[1].legend(['train', 'validation'], loc='best')\n",
    "\n",
    "\n",
    "accuracy_plot(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XziKKzs0xvHy"
   },
   "source": [
    "## Implimenting Bi-LSTM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tEQ3PswjyB7p"
   },
   "source": [
    "## Declaring Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VQASd-y6ylLH"
   },
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "\n",
    "import tensorflow as tf\n",
    "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
    "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from tensorflow.keras.layers import Bidirectional, GlobalMaxPool1D, Conv1D, SimpleRNN\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from tensorflow.keras.layers import Dense, Input, Input, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_nod-MIPx0op",
    "outputId": "3ce72d83-86c0-4af5-92d7-90197d844221"
   },
   "outputs": [],
   "source": [
    "embedding_dim = 64\n",
    "\n",
    "# Model Training\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words,\n",
    "                   embedding_dim,\n",
    "                   input_length=max_sequence_length))\n",
    "\n",
    "# Bidirectional LSTM\n",
    "model.add(Bidirectional(LSTM(16, return_sequences=True, dropout=0.4, recurrent_dropout=0)))\n",
    "\n",
    "model.add(GlobalMaxPool1D())\n",
    "\n",
    "model.add(Dense(5,activation='softmax'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGRpMy_gyvO1"
   },
   "source": [
    "### Training Bi-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I1HrYxDXzN0d",
    "outputId": "a0713b4e-a962-4498-9434-ef2bcb0b5722"
   },
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy', optimizer='RMSProp', metrics = ['accuracy'])\n",
    "# training and validating model\n",
    "history = model.fit(train_data, train_labels, epochs=5,\n",
    "                    validation_data=(test_data, test_labels),\n",
    "                    callbacks=[reduce_lr,early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m6NO3CTnGD1Q",
    "outputId": "cef8b9e3-8a94-4a11-fd97-0dc18fcd842e"
   },
   "outputs": [],
   "source": [
    "# Prediction on Test Data\n",
    "predicted_lstm = model.predict(test_data)\n",
    "predicted_lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O5XYd2ZwG9Rl"
   },
   "source": [
    "### Bi-LSTM Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "khmAkbxEGb-Y",
    "outputId": "cb0f50d9-892b-4486-dff3-8ef03fec27ac"
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "precision, recall, fscore, support = score(test_labels, predicted_lstm.round())\n",
    "\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))\n",
    "print('################################')\n",
    "print(sklearn.metrics.classification_report(test_labels, predicted_lstm.round()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CUei2PJWHTss"
   },
   "source": [
    "### Model Performance with Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 432
    },
    "id": "Mfxh_31yHVUH",
    "outputId": "cd99d850-808d-43da-c064-fa97d28b82e8"
   },
   "outputs": [],
   "source": [
    "def accuracy_plot(history):\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10,4))\n",
    "\n",
    "    fig.suptitle('Model Performance with Epochs', fontsize = 16)\n",
    "    # Subplot 1\n",
    "    ax[0].plot(history.history['accuracy'])\n",
    "    ax[0].plot(history.history['val_accuracy'])\n",
    "    ax[0].set_title('Model Accuracy', fontsize = 14)\n",
    "    ax[0].set_xlabel('Epochs', fontsize = 12)\n",
    "    ax[0].set_ylabel('Accuracy', fontsize = 12)\n",
    "    ax[0].legend(['train', 'validation'], loc='best')\n",
    "\n",
    "    # Subplot 2\n",
    "    ax[1].plot(history.history['loss'])\n",
    "    ax[1].plot(history.history['val_loss'])\n",
    "    ax[1].set_title('Model Loss', fontsize = 14)\n",
    "    ax[1].set_xlabel('Epochs', fontsize = 12)\n",
    "    ax[1].set_ylabel('Loss', fontsize = 12)\n",
    "    ax[1].legend(['train', 'validation'], loc='best')\n",
    "\n",
    "\n",
    "accuracy_plot(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAtnRIabH26Z"
   },
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "gHxmRe1DHeFu",
    "outputId": "ee3de557-b482-4da6-f242-8c71672d1d63"
   },
   "outputs": [],
   "source": [
    "# Declaring function for plotting confusion matrix\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_cm(model, test_data, test_labels):\n",
    "\n",
    "    Rating = ['1', '2', '3', '4', '5']\n",
    "\n",
    "    # Calculate predictions\n",
    "    pred = model.predict(test_data)\n",
    "\n",
    "    # Declaring confusion matrix\n",
    "    cm = confusion_matrix(np.argmax(np.array(test_labels),axis=1), np.argmax(pred, axis=1))\n",
    "\n",
    "    # Heat map labels\n",
    "\n",
    "    group_counts = ['{0:0.0f}'.format(value) for value in cm.flatten()]\n",
    "    group_percentages = ['{0:.2%}'.format(value) for value in cm.flatten()/np.sum(cm)]\n",
    "\n",
    "    labels = [f\"{v2}\\n{v3}\" for v2, v3 in zip(group_counts, group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(5,5)\n",
    "\n",
    "    # Plotting confusion matrix\n",
    "    plt.figure(figsize=(8,4))\n",
    "\n",
    "    sns.heatmap(cm, cmap=plt.cm.Blues, annot=labels, annot_kws={\"size\": 10}, fmt = '',\n",
    "                xticklabels = Rating,\n",
    "                yticklabels = Rating)\n",
    "\n",
    "    plt.xticks(fontsize = 12)\n",
    "    plt.yticks(fontsize = 12, rotation = 'horizontal')\n",
    "    plt.title('Confusion Matrix\\n', fontsize=13)\n",
    "    plt.xlabel('Predicted Labels', fontsize=10)\n",
    "    plt.ylabel('Actual Labels', fontsize=10)\n",
    "\n",
    "plot_cm(model, test_data, test_labels)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
